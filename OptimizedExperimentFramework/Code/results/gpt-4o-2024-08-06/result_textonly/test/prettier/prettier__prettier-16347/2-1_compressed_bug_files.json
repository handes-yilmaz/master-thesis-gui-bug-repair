{
    "1": {
        "bug_file": "src/language-markdown/parser-markdown.js",
        "compressed": "NO",
        "line_numbers": 57,
        "compressed_line_numbers": 57,
        "compressed_bug_file_content": "import footnotes from \"remark-footnotes\";\nimport remarkMath from \"remark-math\";\nimport remarkParse from \"remark-parse\";\nimport unified from \"unified\";\n\nimport { locEnd, locStart } from \"./loc.js\";\nimport { BLOCKS_REGEX, esSyntax } from \"./mdx.js\";\nimport { hasPragma } from \"./pragma.js\";\nimport frontMatter from \"./unified-plugins/front-matter.js\";\nimport htmlToJsx from \"./unified-plugins/html-to-jsx.js\";\nimport liquid from \"./unified-plugins/liquid.js\";\nimport wikiLink from \"./unified-plugins/wiki-link.js\";\n\n/**\n * based on [MDAST](https://github.com/syntax-tree/mdast) with following modifications:\n *\n * 1. restore unescaped character (Text)\n * 2. merge continuous Texts\n * 3. replace whitespaces in InlineCode#value with one whitespace\n *    reference: http://spec.commonmark.org/0.25/#example-605\n * 4. split Text into Sentence\n *\n * interface Word { value: string }\n * interface Whitespace { value: string }\n * interface Sentence { children: Array<Word | Whitespace> }\n * interface InlineCode { children: Array<Sentence> }\n */\nfunction createParse({ isMDX }) {\n  return (text) => {\n    const processor = unified()\n      .use(remarkParse, {\n        commonmark: true,\n        ...(isMDX && { blocks: [BLOCKS_REGEX] }),\n      })\n      .use(footnotes)\n      .use(frontMatter)\n      .use(remarkMath)\n      .use(isMDX ? esSyntax : noop)\n      .use(liquid)\n      .use(isMDX ? htmlToJsx : noop)\n      .use(wikiLink);\n    return processor.run(processor.parse(text));\n  };\n}\n\nfunction noop() {}\n\nconst baseParser = {\n  astFormat: \"mdast\",\n  hasPragma,\n  locStart,\n  locEnd,\n};\n\nexport const markdown = { ...baseParser, parse: createParse({ isMDX: false }) };\nexport const mdx = { ...baseParser, parse: createParse({ isMDX: true }) };\nexport { markdown as remark };"
    },
    "2": {
        "bug_file": "src/language-markdown/printer-markdown.js",
        "compressed": "YES",
        "line_numbers": 779,
        "compressed_line_numbers": 106,
        "compressed_bug_file_content": "import collapseWhiteSpace from \"collapse-white-space\";\n\nimport {\n\n\nimport { DOC_TYPE_STRING } from \"../document/constants.js\";\nimport { getDocType, replaceEndOfLine } from \"../document/utils.js\";\nimport getMaxContinuousCount from \"../utils/get-max-continuous-count.js\";\nimport getMinNotPresentContinuousCount from \"../utils/get-min-not-present-continuous-count.js\";\nimport getPreferredQuote from \"../utils/get-preferred-quote.js\";\nimport UnexpectedNodeError from \"../utils/unexpected-node-error.js\";\nimport clean from \"./clean.js\";\nimport { PUNCTUATION_REGEXP } from \"./constants.evaluate.js\";\nimport embed from \"./embed.js\";\nimport getVisitorKeys from \"./get-visitor-keys.js\";\nimport { locEnd, locStart } from \"./loc.js\";\nimport { insertPragma } from \"./pragma.js\";\nimport { printTable } from \"./print/table.js\";\nimport { printParagraph } from \"./print-paragraph.js\";\nimport preprocess from \"./print-preprocess.js\";\nimport { printSentence } from \"./print-sentence.js\";\nimport { printWhitespace } from \"./print-whitespace.js\";\nimport {\n\n\n/**\n * @typedef {import(\"../document/builders.js\").Doc} Doc\n */\n\n\n    /** @type {Doc} */\n\n\n      /* c8 ignore next 3 */\n\n\n        // backslash is parsed as part of autolinks, so we need to remove it\n\n\n        // leading char that may cause different syntax\n\n\n            // <hello@example.com> is parsed as { url: \"mailto:hello@example.com\" }\n\n\n        // indented code block\n\n\n      // fenced code block\n\n\n        // @ts-expect-error\n\n\n              /* workaround for https://github.com/remarkjs/remark/issues/315 */ node.hasIndentedCodeblock\n\n\n    // `footnote` requires `.use(footnotes, {inlineNotes: true})`, we are not using this option\n    // https://github.com/remarkjs/remark-footnotes#optionsinlinenotes\n    /* c8 ignore next 2 */\n\n\n    // MDX\n    // fallback to the original text if multiparser failed\n    // or `embeddedLanguageFormatting: \"off\"`\n\n\n      // remark-math trims content but we don't want to remove whitespaces\n      // since it's very possible that it's recognized as math accidentally\n\n\n      /* c8 ignore next */\n\n\n  /** @typedef {{ index: number, offset: number }} IgnorePosition */\n  /** @type {Array<{start: IgnorePosition, end: IgnorePosition}>} */\n\n\n  /** @type {IgnorePosition | null} */\n\n\n        // do nothing\n\n\n/** @return {false | 'next' | 'start' | 'end'} */\n\n\n      // Check if `listItem` ends with `\\n`\n      // since it can't be empty, so we only need check the last character\n\n\n/**\n * @param {string} url\n * @param {string[] | string} [dangerousCharOrChars]\n * @returns {string}\n */\n\n\n  // title is escaped after `remark-parse` v7\n\n\n// `remark-parse` lowercase the `label` as `identifier`, we don't want do that\n// https://github.com/remarkjs/remark/blob/daddcb463af2d5b2115496c395d0571c0ff87d15/packages/remark-parse/lib/tokenize/reference.js\n\n\nexport default printer;\n"
    },
    "3": {
        "bug_file": "src/language-markdown/utils.js",
        "compressed": "NO",
        "line_numbers": 253,
        "compressed_line_numbers": 253,
        "compressed_bug_file_content": "import assert from \"node:assert\";\n\nimport {\n  CJK_REGEXP,\n  K_REGEXP,\n  PUNCTUATION_REGEXP,\n} from \"./constants.evaluate.js\";\nimport { locEnd, locStart } from \"./loc.js\";\n\nconst INLINE_NODE_TYPES = new Set([\n  \"liquidNode\",\n  \"inlineCode\",\n  \"emphasis\",\n  \"esComment\",\n  \"strong\",\n  \"delete\",\n  \"wikiLink\",\n  \"link\",\n  \"linkReference\",\n  \"image\",\n  \"imageReference\",\n  \"footnote\",\n  \"footnoteReference\",\n  \"sentence\",\n  \"whitespace\",\n  \"word\",\n  \"break\",\n  \"inlineMath\",\n]);\n\nconst INLINE_NODE_WRAPPER_TYPES = new Set([\n  ...INLINE_NODE_TYPES,\n  \"tableCell\",\n  \"paragraph\",\n  \"heading\",\n]);\n\nconst KIND_NON_CJK = \"non-cjk\";\nconst KIND_CJ_LETTER = \"cj-letter\";\nconst KIND_K_LETTER = \"k-letter\";\nconst KIND_CJK_PUNCTUATION = \"cjk-punctuation\";\n\n/**\n * @typedef {\" \" | \"\\n\" | \"\"} WhitespaceValue\n * @typedef { KIND_NON_CJK | KIND_CJ_LETTER | KIND_K_LETTER | KIND_CJK_PUNCTUATION } WordKind\n * @typedef {{\n *   type: \"whitespace\",\n *   value: WhitespaceValue,\n *   kind?: never\n * }} WhitespaceNode\n * @typedef {{\n *   type: \"word\",\n *   value: string,\n *   kind: WordKind,\n *   hasLeadingPunctuation: boolean,\n *   hasTrailingPunctuation: boolean,\n * }} WordNode\n * Node for a single CJK character or a sequence of non-CJK characters\n * @typedef {WhitespaceNode | WordNode} TextNode\n */\n\n/**\n * split text into whitespaces and words\n * @param {string} text\n */\nfunction splitText(text) {\n  /** @type {Array<TextNode>} */\n  const nodes = [];\n\n  const tokens = text.split(/([\\t\\n ]+)/);\n  for (const [index, token] of tokens.entries()) {\n    // whitespace\n    if (index % 2 === 1) {\n      nodes.push({\n        type: \"whitespace\",\n        value: /\\n/.test(token) ? \"\\n\" : \" \",\n      });\n      continue;\n    }\n\n    // word separated by whitespace\n\n    if ((index === 0 || index === tokens.length - 1) && token === \"\") {\n      continue;\n    }\n\n    const innerTokens = token.split(new RegExp(`(${CJK_REGEXP.source})`));\n    for (const [innerIndex, innerToken] of innerTokens.entries()) {\n      if (\n        (innerIndex === 0 || innerIndex === innerTokens.length - 1) &&\n        innerToken === \"\"\n      ) {\n        continue;\n      }\n\n      // non-CJK word\n      if (innerIndex % 2 === 0) {\n        if (innerToken !== \"\") {\n          appendNode({\n            type: \"word\",\n            value: innerToken,\n            kind: KIND_NON_CJK,\n            hasLeadingPunctuation: PUNCTUATION_REGEXP.test(innerToken[0]),\n            hasTrailingPunctuation: PUNCTUATION_REGEXP.test(innerToken.at(-1)),\n          });\n        }\n        continue;\n      }\n\n      // CJK character\n      appendNode(\n        PUNCTUATION_REGEXP.test(innerToken)\n          ? {\n              type: \"word\",\n              value: innerToken,\n              kind: KIND_CJK_PUNCTUATION,\n              hasLeadingPunctuation: true,\n              hasTrailingPunctuation: true,\n            }\n          : {\n              type: \"word\",\n              value: innerToken,\n              // Korean uses space to divide words, but Chinese & Japanese do not\n              kind: K_REGEXP.test(innerToken) ? KIND_K_LETTER : KIND_CJ_LETTER,\n              hasLeadingPunctuation: false,\n              hasTrailingPunctuation: false,\n            },\n      );\n    }\n  }\n\n  // Check for `canBeConvertedToSpace` in ./print-whitespace.js etc.\n  if (process.env.NODE_ENV !== \"production\") {\n    for (let i = 1; i < nodes.length; i++) {\n      assert(\n        !(nodes[i - 1].type === \"whitespace\" && nodes[i].type === \"whitespace\"),\n        \"splitText should not create consecutive whitespace nodes\",\n      );\n    }\n  }\n\n  return nodes;\n\n  function appendNode(node) {\n    const lastNode = nodes.at(-1);\n    if (\n      lastNode?.type === \"word\" &&\n      !isBetween(KIND_NON_CJK, KIND_CJK_PUNCTUATION) &&\n      // disallow leading/trailing full-width whitespace\n      ![lastNode.value, node.value].some((value) => /\\u3000/.test(value))\n    ) {\n      nodes.push({ type: \"whitespace\", value: \"\" });\n    }\n    nodes.push(node);\n\n    function isBetween(kind1, kind2) {\n      return (\n        (lastNode.kind === kind1 && node.kind === kind2) ||\n        (lastNode.kind === kind2 && node.kind === kind1)\n      );\n    }\n  }\n}\n\nfunction getOrderedListItemInfo(orderListItem, originalText) {\n  const [, numberText, marker, leadingSpaces] = originalText\n    .slice(\n      orderListItem.position.start.offset,\n      orderListItem.position.end.offset,\n    )\n    .match(/^\\s*(\\d+)(\\.|\\))(\\s*)/);\n\n  return { numberText, marker, leadingSpaces };\n}\n\nfunction hasGitDiffFriendlyOrderedList(node, options) {\n  if (!node.ordered) {\n    return false;\n  }\n\n  if (node.children.length < 2) {\n    return false;\n  }\n\n  const firstNumber = Number(\n    getOrderedListItemInfo(node.children[0], options.originalText).numberText,\n  );\n\n  const secondNumber = Number(\n    getOrderedListItemInfo(node.children[1], options.originalText).numberText,\n  );\n\n  if (firstNumber === 0 && node.children.length > 2) {\n    const thirdNumber = Number(\n      getOrderedListItemInfo(node.children[2], options.originalText).numberText,\n    );\n\n    return secondNumber === 1 && thirdNumber === 1;\n  }\n\n  return secondNumber === 1;\n}\n\n// The final new line should not include in value\n// https://github.com/remarkjs/remark/issues/512\nfunction getFencedCodeBlockValue(node, originalText) {\n  const { value } = node;\n  if (\n    node.position.end.offset === originalText.length &&\n    value.endsWith(\"\\n\") &&\n    // Code block has no end mark\n    originalText.endsWith(\"\\n\")\n  ) {\n    return value.slice(0, -1);\n  }\n  return value;\n}\n\nfunction mapAst(ast, handler) {\n  return (function preorder(node, index, parentStack) {\n    const newNode = { ...handler(node, index, parentStack) };\n    if (newNode.children) {\n      newNode.children = newNode.children.map((child, index) =>\n        preorder(child, index, [newNode, ...parentStack]),\n      );\n    }\n\n    return newNode;\n  })(ast, null, []);\n}\n\nfunction isAutolink(node) {\n  if (node?.type !== \"link\" || node.children.length !== 1) {\n    return false;\n  }\n  const [child] = node.children;\n  return locStart(node) === locStart(child) && locEnd(node) === locEnd(child);\n}\n\nexport {\n  getFencedCodeBlockValue,\n  getOrderedListItemInfo,\n  hasGitDiffFriendlyOrderedList,\n  INLINE_NODE_TYPES,\n  INLINE_NODE_WRAPPER_TYPES,\n  isAutolink,\n  KIND_CJ_LETTER,\n  KIND_CJK_PUNCTUATION,\n  KIND_K_LETTER,\n  KIND_NON_CJK,\n  mapAst,\n  splitText,\n};"
    },
    "4": {
        "bug_file": "src/language-markdown/unified-plugins/front-matter.js",
        "compressed": "NO",
        "line_numbers": 21,
        "compressed_line_numbers": 21,
        "compressed_bug_file_content": "import parseFrontMatter from \"../../utils/front-matter/parse.js\";\n\n/**\n * @type {import('unified').Plugin<[], import('unified').Settings>}\n */\nconst frontMatter = function () {\n  const proto = this.Parser.prototype;\n  proto.blockMethods = [\"frontMatter\", ...proto.blockMethods];\n  proto.blockTokenizers.frontMatter = tokenizer;\n\n  function tokenizer(eat, value) {\n    const parsed = parseFrontMatter(value);\n\n    if (parsed.frontMatter) {\n      return eat(parsed.frontMatter.raw)(parsed.frontMatter);\n    }\n  }\n  tokenizer.onlyAtStart = true;\n};\n\nexport default frontMatter;"
    },
    "5": {
        "bug_file": "src/utils/front-matter/parse.js",
        "compressed": "NO",
        "line_numbers": 48,
        "compressed_line_numbers": 48,
        "compressed_bug_file_content": "const frontMatterRegex = new RegExp(\n  String.raw`^(?<startDelimiter>-{3}|\\+{3})` +\n    // trailing spaces after delimiters are allowed\n    String.raw`(?<language>[^\\n]*)` +\n    String.raw`\\n(?:|(?<value>.*?)\\n)` +\n    // In some markdown processors such as pandoc,\n    // \"...\" can be used as the end delimiter for YAML front-matter.\n    // Adding `\\.{3}` make the regex matches `+++\\n...`, but we'll exclude it later\n    String.raw`(?<endDelimiter>\\k<startDelimiter>|\\.{3})` +\n    String.raw`[^\\S\\n]*(?:\\n|$)`,\n  \"s\",\n);\n\nfunction parse(text) {\n  const match = text.match(frontMatterRegex);\n  if (!match) {\n    return { content: text };\n  }\n\n  const { startDelimiter, language, value = \"\", endDelimiter } = match.groups;\n\n  let lang = language.trim() || \"yaml\";\n  if (startDelimiter === \"+++\") {\n    lang = \"toml\";\n  }\n\n  // Only allow yaml to parse with a different end delimiter\n  if (lang !== \"yaml\" && startDelimiter !== endDelimiter) {\n    return { content: text };\n  }\n\n  const [raw] = match;\n  const frontMatter = {\n    type: \"front-matter\",\n    lang,\n    value,\n    startDelimiter,\n    endDelimiter,\n    raw: raw.replace(/\\n$/, \"\"),\n  };\n\n  return {\n    frontMatter,\n    content: raw.replaceAll(/[^\\n]/g, \" \") + text.slice(raw.length),\n  };\n}\n\nexport default parse;"
    },
    "6": {
        "bug_file": "src/utils/front-matter/is-front-matter.js",
        "compressed": "NO",
        "line_numbers": 5,
        "compressed_line_numbers": 5,
        "compressed_bug_file_content": "function isFrontMatter(node) {\n  return node?.type === \"front-matter\";\n}\n\nexport default isFrontMatter;"
    }
}